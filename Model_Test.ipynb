{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df74734c-8768-49dd-bf4c-7d78b2ad51e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59a58bdb-f1b0-4c01-bde9-e140369d642a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('Playlist_data_with_lyrics.csv')\n",
    "artists = pd.read_csv('artists.csv')\n",
    "df = pd.read_csv('playlist_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00c77408-07b8-4954-9484-fa0ca56deff2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Playlist_ID</th>\n",
       "      <th>Playlist_Name</th>\n",
       "      <th>Playlist_Description</th>\n",
       "      <th>Playlist_Songs</th>\n",
       "      <th>Playlist_Artists</th>\n",
       "      <th>Playlist_Song_IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6mtYuOxzl58vSGnEDtZ9uB</td>\n",
       "      <td>Pop Hits 2000s â€“ 2025</td>\n",
       "      <td>old but gold, all the best throwback songs to ...</td>\n",
       "      <td>['Into You', 'Glad You Came', 'Dark Horse', 'W...</td>\n",
       "      <td>['Ariana Grande', 'The Wanted', 'Katy Perry', ...</td>\n",
       "      <td>['2meEiZKWkiN28gITzFwQo5', '1OXfWI3FQMdsKKC6lk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4Jb4PDWREzNnbZcOHPcZPy</td>\n",
       "      <td>COUNTRY HITS 2025 ðŸ”¥ New Country Songs + Top Hits</td>\n",
       "      <td>best country music of 2025 most popular trendi...</td>\n",
       "      <td>['I Had Some Help (Feat. Morgan Wallen)', \"Aus...</td>\n",
       "      <td>['Post Malone', 'Dasha', 'mgk', 'Dylan Marlowe...</td>\n",
       "      <td>['5IZXB5IKAD2qlvTPJYDCFB', '2uqYupMHANxnwgeiXT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2L2HwKRvUgBv1YetudaRI3</td>\n",
       "      <td>Pop 2000-2010 Bangers</td>\n",
       "      <td>Some bangers, but no mash</td>\n",
       "      <td>['Whatcha Say', 'Airplanes (feat. Hayley Willi...</td>\n",
       "      <td>['Jason Derulo', 'B.o.B', 'Bruno Mars', 'Tinch...</td>\n",
       "      <td>['7xkQdy0cy5ymoWT7nedvLz', '1QnvpPFP4Q3FHbDchq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>327k1ryJ7j1xD7gWKpdc6o</td>\n",
       "      <td>Popular Christian Music</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Oh My Soul', 'Stars', 'Voice of Truth', 'You...</td>\n",
       "      <td>['Casting Crowns', 'Skillet', 'Casting Crowns'...</td>\n",
       "      <td>['3s0h3pyKFrS3XX6ZLBPx6s', '6VMT3SzIMbNoR5lsUs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4muHyvSwG1wP9sI4XihC5w</td>\n",
       "      <td>Instrumental Popular Songs 2025</td>\n",
       "      <td>Instrumental Popular Songs of 2025, 2024, Upda...</td>\n",
       "      <td>['birds of a feather - piano instrumental', 'g...</td>\n",
       "      <td>['Chilled Pig', 'Chilled Pig', 'Chilled Pig', ...</td>\n",
       "      <td>['1bE4hvWlx8gtWIMVUptOXi', '1KYe04kDLflLdoJ9kN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>51e9GT8ZX12eLk3U0ZKYpP</td>\n",
       "      <td>Godzilla (Clean)</td>\n",
       "      <td>(Clean) (Eminem)</td>\n",
       "      <td>['Godzilla (feat. Juice WRLD)', 'Godzilla (fea...</td>\n",
       "      <td>['Eminem', 'Eminem', 'Eminem', 'KPH']</td>\n",
       "      <td>['7kP9UmZiA6YN2S3w5XObGN', '1519ABUWhVwCx3Eyvn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2285</th>\n",
       "      <td>2VLi4fjkYPtJomgOoIaj0C</td>\n",
       "      <td>Old (2000's) Eminem Songs</td>\n",
       "      <td>young eminem list (Without Me , Mockinbird , T...</td>\n",
       "      <td>['Without Me', 'Mockingbird', 'Lose Yourself',...</td>\n",
       "      <td>['Eminem', 'Eminem', 'Eminem', 'Eminem', 'Emin...</td>\n",
       "      <td>['7lQ8MOhq6IN2w8EYcFNSUk', '561jH07mF1jHuk7Kla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2286</th>\n",
       "      <td>2WdRzPntCC3OIrov4OJgok</td>\n",
       "      <td>all Eminem albums in order</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Infinite', 'Public Service Announcement', 'M...</td>\n",
       "      <td>['Eminem', 'Eminem', 'Eminem', 'Eminem', 'Emin...</td>\n",
       "      <td>['01xhMrdCefADl7HSttJaf7', '3GhcNCBIEMyrcpCJ8c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2287</th>\n",
       "      <td>1EGau2utUnkCD50M3Iu1gT</td>\n",
       "      <td>MGK VS EMINEM</td>\n",
       "      <td>This is the beef between MGK and Eminem. The d...</td>\n",
       "      <td>['No Reason (The Mosh Pit Song)', \"Not Alike (...</td>\n",
       "      <td>['Tech N9ne', 'Eminem', 'mgk', 'Eminem']</td>\n",
       "      <td>['0tdl6DyOBsgfGzQ0kfjvdh', '28FGV3ORH14MYORd7s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288</th>\n",
       "      <td>1dK4nLwc89eaFR0OWSm6yZ</td>\n",
       "      <td>ALL of Eminems Songs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['3 a.m.', 'My Mom', 'Insane', 'Bagpipes From ...</td>\n",
       "      <td>['Eminem', 'Eminem', 'Eminem', 'Eminem', 'Emin...</td>\n",
       "      <td>['7Djpvy4lZJNI8rTOVLf1H7', '2ruw2Kq8lgyqwemZik...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2289 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Playlist_ID  \\\n",
       "0     6mtYuOxzl58vSGnEDtZ9uB   \n",
       "1     4Jb4PDWREzNnbZcOHPcZPy   \n",
       "2     2L2HwKRvUgBv1YetudaRI3   \n",
       "3     327k1ryJ7j1xD7gWKpdc6o   \n",
       "4     4muHyvSwG1wP9sI4XihC5w   \n",
       "...                      ...   \n",
       "2284  51e9GT8ZX12eLk3U0ZKYpP   \n",
       "2285  2VLi4fjkYPtJomgOoIaj0C   \n",
       "2286  2WdRzPntCC3OIrov4OJgok   \n",
       "2287  1EGau2utUnkCD50M3Iu1gT   \n",
       "2288  1dK4nLwc89eaFR0OWSm6yZ   \n",
       "\n",
       "                                         Playlist_Name  \\\n",
       "0                                Pop Hits 2000s â€“ 2025   \n",
       "1     COUNTRY HITS 2025 ðŸ”¥ New Country Songs + Top Hits   \n",
       "2                                Pop 2000-2010 Bangers   \n",
       "3                              Popular Christian Music   \n",
       "4                      Instrumental Popular Songs 2025   \n",
       "...                                                ...   \n",
       "2284                                  Godzilla (Clean)   \n",
       "2285                        Old (2000's) Eminem Songs    \n",
       "2286                        all Eminem albums in order   \n",
       "2287                                     MGK VS EMINEM   \n",
       "2288                              ALL of Eminems Songs   \n",
       "\n",
       "                                   Playlist_Description  \\\n",
       "0     old but gold, all the best throwback songs to ...   \n",
       "1     best country music of 2025 most popular trendi...   \n",
       "2                             Some bangers, but no mash   \n",
       "3                                                   NaN   \n",
       "4     Instrumental Popular Songs of 2025, 2024, Upda...   \n",
       "...                                                 ...   \n",
       "2284                                   (Clean) (Eminem)   \n",
       "2285  young eminem list (Without Me , Mockinbird , T...   \n",
       "2286                                                NaN   \n",
       "2287  This is the beef between MGK and Eminem. The d...   \n",
       "2288                                                NaN   \n",
       "\n",
       "                                         Playlist_Songs  \\\n",
       "0     ['Into You', 'Glad You Came', 'Dark Horse', 'W...   \n",
       "1     ['I Had Some Help (Feat. Morgan Wallen)', \"Aus...   \n",
       "2     ['Whatcha Say', 'Airplanes (feat. Hayley Willi...   \n",
       "3     ['Oh My Soul', 'Stars', 'Voice of Truth', 'You...   \n",
       "4     ['birds of a feather - piano instrumental', 'g...   \n",
       "...                                                 ...   \n",
       "2284  ['Godzilla (feat. Juice WRLD)', 'Godzilla (fea...   \n",
       "2285  ['Without Me', 'Mockingbird', 'Lose Yourself',...   \n",
       "2286  ['Infinite', 'Public Service Announcement', 'M...   \n",
       "2287  ['No Reason (The Mosh Pit Song)', \"Not Alike (...   \n",
       "2288  ['3 a.m.', 'My Mom', 'Insane', 'Bagpipes From ...   \n",
       "\n",
       "                                       Playlist_Artists  \\\n",
       "0     ['Ariana Grande', 'The Wanted', 'Katy Perry', ...   \n",
       "1     ['Post Malone', 'Dasha', 'mgk', 'Dylan Marlowe...   \n",
       "2     ['Jason Derulo', 'B.o.B', 'Bruno Mars', 'Tinch...   \n",
       "3     ['Casting Crowns', 'Skillet', 'Casting Crowns'...   \n",
       "4     ['Chilled Pig', 'Chilled Pig', 'Chilled Pig', ...   \n",
       "...                                                 ...   \n",
       "2284              ['Eminem', 'Eminem', 'Eminem', 'KPH']   \n",
       "2285  ['Eminem', 'Eminem', 'Eminem', 'Eminem', 'Emin...   \n",
       "2286  ['Eminem', 'Eminem', 'Eminem', 'Eminem', 'Emin...   \n",
       "2287           ['Tech N9ne', 'Eminem', 'mgk', 'Eminem']   \n",
       "2288  ['Eminem', 'Eminem', 'Eminem', 'Eminem', 'Emin...   \n",
       "\n",
       "                                      Playlist_Song_IDs  \n",
       "0     ['2meEiZKWkiN28gITzFwQo5', '1OXfWI3FQMdsKKC6lk...  \n",
       "1     ['5IZXB5IKAD2qlvTPJYDCFB', '2uqYupMHANxnwgeiXT...  \n",
       "2     ['7xkQdy0cy5ymoWT7nedvLz', '1QnvpPFP4Q3FHbDchq...  \n",
       "3     ['3s0h3pyKFrS3XX6ZLBPx6s', '6VMT3SzIMbNoR5lsUs...  \n",
       "4     ['1bE4hvWlx8gtWIMVUptOXi', '1KYe04kDLflLdoJ9kN...  \n",
       "...                                                 ...  \n",
       "2284  ['7kP9UmZiA6YN2S3w5XObGN', '1519ABUWhVwCx3Eyvn...  \n",
       "2285  ['7lQ8MOhq6IN2w8EYcFNSUk', '561jH07mF1jHuk7Kla...  \n",
       "2286  ['01xhMrdCefADl7HSttJaf7', '3GhcNCBIEMyrcpCJ8c...  \n",
       "2287  ['0tdl6DyOBsgfGzQ0kfjvdh', '28FGV3ORH14MYORd7s...  \n",
       "2288  ['7Djpvy4lZJNI8rTOVLf1H7', '2ruw2Kq8lgyqwemZik...  \n",
       "\n",
       "[2289 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa5a839c-8956-4094-968b-606271d81f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert stringified lists to Python lists if needed\n",
    "import ast\n",
    "for col in ['Playlist_Songs', 'Playlist_Artists', 'Playlist_Song_IDs']:\n",
    "    df[col] = df[col].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "# Build target output string: \"Song1 by Artist1, Song2 by Artist2, ...\"\n",
    "def build_output_text(row):\n",
    "    songs = row['Playlist_Songs']\n",
    "    artists = row['Playlist_Artists']\n",
    "    paired = [f\"{s} by {a}\" for s, a in zip(songs, artists)]\n",
    "    return ', '.join(paired)\n",
    "\n",
    "# Build final dataset\n",
    "df['input_text'] = df['Playlist_Name']\n",
    "df['target_text'] = df.apply(build_output_text, axis=1)\n",
    "\n",
    "# Split into train and validation\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['input_text'].tolist(),\n",
    "    df['target_text'].tolist(),\n",
    "    test_size=0.2\n",
    ")\n",
    "\n",
    "train_data = Dataset.from_dict({'input_text': train_texts, 'label': train_labels})\n",
    "val_data = Dataset.from_dict({'input_text': val_texts, 'label': val_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8afe4be6-a9c1-48bc-9c13-b2495b4d3c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1460/1460 [00:01<00:00, 1047.41 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 366/366 [00:00<00:00, 1082.65 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "\n",
    "# Tokenize input and label\n",
    "def tokenize(batch):\n",
    "    input_encodings = tokenizer(batch['input_text'], padding=\"max_length\", truncation=True, max_length=64)\n",
    "    label_encodings = tokenizer(batch['label'], padding=\"max_length\", truncation=True, max_length=256)\n",
    "    input_encodings[\"labels\"] = label_encodings[\"input_ids\"]\n",
    "    return input_encodings\n",
    "\n",
    "train_data = train_data.map(tokenize, batched=True)\n",
    "val_data = val_data.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0273bb21-41ba-45a5-97ee-0340d5bb1769",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TrainingArguments, Trainer\n\u001b[0;32m----> 3\u001b[0m training_args \u001b[38;5;241m=\u001b[39m \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./t5_playlist_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mno\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogging_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./logs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     15\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     16\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m     17\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_data,\n\u001b[1;32m     18\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mval_data\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     21\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "\u001b[0;31mTypeError\u001b[0m: TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./t5_playlist_model\",\n",
    "    evaluation_strategy=\"no\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=4,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fa3b57-7561-4048-8a21-85b8ee0ef517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_playlist(prompt, max_length=128):\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "    output = model.generate(input_ids, max_length=max_length, temperature=0.8)\n",
    "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return decoded\n",
    "\n",
    "# Example prompt\n",
    "prompt = \"Road trip anthems for 2020s pop hits\"\n",
    "print(generate_playlist(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f2f091-86d5-4ed7-905d-a7a1071c3953",
   "metadata": {},
   "source": [
    "# GPT Model w/o Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a19eba1-e4d4-4e3a-a398-6e9a28476948",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "import ast\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "270efa3e-de10-4730-afca-f9752a0f8024",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "import ast\n",
    "\n",
    "# Load and parse the dataset\n",
    "\n",
    "# Convert stringified lists to actual lists\n",
    "for col in ['Playlist_Songs', 'Playlist_Artists']:\n",
    "    df[col] = df[col].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "## Training Targets 1st Iteration, 3 epoch Loss ~ 3, 5 epoch Loss ~ 2.5\n",
    "# Create prompt + output text for GPT-2 training\n",
    "# def format_example(row):\n",
    "#     song_lines = [f\"{s} - {a}\" for s, a in zip(row['Playlist_Songs'], row['Playlist_Artists'])]\n",
    "#     return f\"### Prompt: {row['Playlist_Name']}\\n### Playlist:\\n\" + \"\\n\".join(song_lines)\n",
    "\n",
    "## Training Targets 2nd Iteration, 5 epoch Loss ~ 1.3\n",
    "# def format_example(row):\n",
    "#     lines = [f\"[SONG] {s} [ARTIST] {a}\" for s, a in zip(row[\"Playlist_Songs\"], row[\"Playlist_Artists\"])]\n",
    "#     return f\"### Prompt: {row['Playlist_Name']}\\n### Playlist:\\n\" + \"\\n\".join(lines)\n",
    "\n",
    "## Training targets 3rd Iteration, 5 epoch Loss ~ \n",
    "def format_example(row):\n",
    "    lines = [f\"[SONG] {song} [ARTIST] {artist}\" for song, artist in zip(row[\"Playlist_Songs\"], row[\"Playlist_Artists\"])]\n",
    "    playlist_body = \"\\n\".join(lines)\n",
    "    \n",
    "    # Include Playlist_Description in the prompt for training only\n",
    "    return (\n",
    "        f\"### Prompt: {row['Playlist_Name']}\\n\"\n",
    "        f\"### Description: {row['Playlist_Description']}\\n\"\n",
    "        f\"### Playlist:\\n{playlist_body}\"\n",
    "    )\n",
    "\n",
    "df['text'] = df.apply(format_example, axis=1)\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "dataset = Dataset.from_dict({\"text\": df['text'].tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a9fcd7f-fe4f-487a-99ff-c9c48600e881",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "686055f8abe74319bf0db2df5095a452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2289 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-medium\")\n",
    "tokenizer.pad_token = tokenizer.eos_token  # GPT-2 doesn't have a pad token\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2-medium\")\n",
    "model.resize_token_embeddings(len(tokenizer))  # In case we add special tokens\n",
    "\n",
    "# Tokenize\n",
    "def tokenize(batch):\n",
    "    encodings = tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "    encodings[\"labels\"] = encodings[\"input_ids\"].copy()  # ðŸ”¥ Add this line\n",
    "    return encodings\n",
    "    \n",
    "tokenized_dataset = dataset.map(tokenize, batched=True)\n",
    "tokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8b1a832-3911-48d6-8d45-3b84f2394e9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5725' max='5725' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5725/5725 18:57, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.354300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.985500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.878700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.854000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.772700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.782800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.803600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.711200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.676800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.683000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.657800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>1.709700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.664400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.715700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.628800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>1.726700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.683500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>1.716200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.594500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>1.641300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.638500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>1.524800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.496200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>1.402200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.393800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>1.528000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.451600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>1.469100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.415400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>1.485500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.510400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>1.525800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>1.432500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>1.449200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.438800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>1.423400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>1.425200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>1.412900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.480700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>1.375200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>1.425200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>1.425700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>1.402100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>1.483700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>1.447700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>1.268400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.262400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>1.324800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.278700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>1.342300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>1.342600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>1.329600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>1.232200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>1.241200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>1.336600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>1.334400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>1.315900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>1.319600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.319600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>1.340700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>1.306300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>1.315800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>1.298800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>1.281700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>1.220600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>1.258500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>1.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>1.267600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.133500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>1.167500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>1.193700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>1.258000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>1.186900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>1.189500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>1.272100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3850</td>\n",
       "      <td>1.123500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>1.209700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3950</td>\n",
       "      <td>1.156600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.078600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4050</td>\n",
       "      <td>1.179600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>1.178600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4150</td>\n",
       "      <td>1.186200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>1.223600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>1.234100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>1.172000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4350</td>\n",
       "      <td>1.236300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>1.158000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4450</td>\n",
       "      <td>1.212500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.192000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4550</td>\n",
       "      <td>1.216400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>1.128800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4650</td>\n",
       "      <td>1.078500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>1.104700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4750</td>\n",
       "      <td>1.110800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>1.189600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4850</td>\n",
       "      <td>1.027200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>1.184700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4950</td>\n",
       "      <td>1.101700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.091700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5050</td>\n",
       "      <td>1.123400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>1.192000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5150</td>\n",
       "      <td>1.104100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>1.100300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5250</td>\n",
       "      <td>1.146800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>1.110800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5350</td>\n",
       "      <td>1.137800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>1.184000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5450</td>\n",
       "      <td>1.096900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>1.113000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5550</td>\n",
       "      <td>1.113000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>1.100700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5650</td>\n",
       "      <td>1.136400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>1.114900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5725, training_loss=1.359067278866164, metrics={'train_runtime': 1138.0674, 'train_samples_per_second': 10.057, 'train_steps_per_second': 5.03, 'total_flos': 1.062897944887296e+16, 'train_loss': 1.359067278866164, 'epoch': 5.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2_playlist_model_w_Descriptions\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=2,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    fp16=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5ad9200-c296-4dfa-aef3-3f60f9e76d5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SONG] Viva La Vida (feat. Dua Lipa) [ARTIST] Pitbull\n",
      "[SONG] Fergalicious [ARTIST] Fergie\n",
      "[SONG] Only Girl (In The World) [ARTIST] Rihanna\n",
      "[SONG] Whatcha Say [ARTIST] Jason Derulo\n",
      "[SONG] All Star [ARTIST] The Weeknd\n",
      "[SONG] Bitch Better Have My Money [ARTIST] Rihanna\n",
      "[SONG] Don't Cha [ARTIST] The Pussycat Dolls\n",
      "[SONG] Promiscuous [ARTIST] Nelly Furtado\n",
      "[SONG] DJ Got Us Fallin' In Love (feat. Pitbull) [ARTIST] USHER\n",
      "[SONG] Hot N*gga [ARTIST] Petey Pablo\n",
      "[SONG] Ti\n"
     ]
    }
   ],
   "source": [
    "def generate_playlist(prompt, max_length=200):\n",
    "    input_text = f\"### Prompt: {prompt}\\n### Playlist:\\n\"\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "\n",
    "    output = model.generate(\n",
    "        input_ids = input_ids.to('cuda'),\n",
    "        max_length=max_length,\n",
    "        temperature=0.9,\n",
    "        top_p=0.95,\n",
    "        do_sample=True,\n",
    "        num_return_sequences=1,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    result = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return result.split(\"### Playlist:\\n\")[1].strip()\n",
    "\n",
    "# Try it out!\n",
    "prompt = \"I want to dance\"\n",
    "print(generate_playlist(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9de8892a-453c-4155-9695-80f85cb0499e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1826"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Import Saved Model and use with generate_playlist function\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(\"./gpt2_playlist_model\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"./gpt2_playlist_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba71d2b5-c544-4b0c-b9df-4245b94bc878",
   "metadata": {},
   "source": [
    "# GPT Model w/ Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b419fc2-fc18-4e17-b071-fa13e2b6f572",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (test)",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
